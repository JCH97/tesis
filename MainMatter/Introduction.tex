%\chapter*{Introducción}\label{chapter:introduction}
\begin{introduction}
	Desde tiempos de antaño el hombre se ha visto en la necesidad imperiosa de manejar de la manera más adecuada posible sus recursos, no solo para conseguir prolongar la vida de estos, sino además para contar con una aceptada utilización de los mismos. Uno de los principales problemas que aqueja a la sociedad actual es la dificultad que se presenta para garantizar un óptimo manejo de nuestro \textit{tiempo}.
	
	La denominada \textit{gestión del tiempo} hace referencia a la forma en que cada uno organiza y planifica cuánto tiempo invierte en actividades específicas. Pasar más horas en la empresa no significa ser más eficiente o productivo. Por ello, es fundamental una adecuada gestión del tiempo en el trabajo, lo que permitiría lograr más con menos esfuerzo. Cuando se aprende a administrar nuestro día se mejora la capacidad de concentración, lo que trae consigo un mayor enfoque y por tanto una mayor eficiencia. Gestionar el tiempo nos permite realizar las tareas con más rapidez y que la jornada laboral sea más efectiva y se aproveche mejor.
	
	En muchos escenarios cotidianos la planificación de las actividades se realiza solamente de manera irreal, por otro lado, existen ámbitos donde se hace necesario garantizar una manipulación detallada de todo el proceso productivo.
	
	Con la llegada de las tecnologías actuales y la facilidad con que las personas cambian de actividad, el desarrollo de un software que garantice una plaificación de nuestra agenda diaria, resulta casi imprescindible.
	
	
	
	
	
	Hace unos 70000 años, nuestra especie, \textit{Homo Sapiens}, experimentó un salto evolutivo que le dotó de capacidades para socializarse y modificar su entorno como ninguna otra sobre la Tierra. Algunos autores llaman a este salto la Revolución Cognitiva. En su libro \textit{Sapiens: Una breve historia de la humanidad }, el historiador Yuval Noah Harari plantea que este salto consistió en la adquisición de la capacidad de imaginar entidades ficticias, lo cual permitió que grandes cantidades de desconocidos que compartían las mismas creencias cooperaran entre sí y conquistaran el planeta.\cite{harari2014sapiens}
	
	La capacidad de imaginar está estrechamente vinculada con el pensamiento causal.
	Al imaginar las consecuencias de una acción con anticipación, aun sin llegar a ejecutarla, estamos estimando el efecto de una \textit{intervención}. Por otra parte, formular preguntas acerca de mundos alternativos a partir de experiencias observadas en el real, se conoce como \textit{contrafactual}. Antes de la Revolución Cognitiva, nuestra especie se limitaba a observar el mundo, infiriendo hechos a partir de las experiencias vividas. Sin embargo, la adquisición de estas nuevas habilidades transformó a \textit{Homo Sapiens} en un razonador causal. Hasta ahora el único ser vivo que se conoce que tiene esta capacidad es nuestra especie y por tanto podría ser un factor clave si queremos simular la inteligencia humana.
	
	En la actualidad, los algoritmos de IA se basan principalmente en el reconocimiento de patrones. Para ello necesitan ser entrenados con grandes cantidades de datos. Las increíbles habilidades que han demostrado estos algoritmos en algunas tareas ha llevado a pensar a algunos que la inteligencia humana se reduce al mero procesamiento de datos. Sin embargo, es evidente que la IA se encuentra todavía lejos de igualar a la inteligencia humana en muchos aspectos. Algunos autores, entre ellos Judea Pearl, plantean que la pieza faltante para lograr construir una verdadera inteligencia artificial consiste en dotar a las máquinas de razonamiento causal.\cite{PearlMackenzie18}
	
	A partir de la afirmación de Pearl, sería oportuno realizarse algunas preguntas:
	\begin{itemize}
		\item \textquestiondown Qué ventajas posee dotar de razonamiento causal a un programa de inteligencia artificial ?
		\item \textquestiondown  Cuáles son los principales desarrollos alacanzados hasta la fecha en el área científica de la causalidad ?
		\item \textquestiondown Cuales son las aplicaciones que tiene la causalidad en la actualidad ?
	\end{itemize}
	El presente trabajo pretende arrojar algunas luces en torno a estas cuestiones. En particular, se demostrará cómo, con los desarrollos alcanzados en esta área, se pueden desarrollar herramientas que basándose en la inferencia causal permitan resolver problemas prácticos en la actualidad.
	
	A continuación se recorrerán los momentos más importantes de la historia de la causalidad en la filosofía y la ciencia. Se verá como esta fue excluida de la ciencia por los estadísticos, y los problemas que surgieron a partir de esta exclusión. Luego se resaltarán los principales exponentes de la teoría de la causalidad junto con sus más notables avances.
	
	\section{Un poco de historia}
	Definir la causalidad fue una tarea que comenzó en manos de los filósofos. Ya en la antigua Grecia, Aristóteles atribuyó a la palabra causa varios significados \cite{aristotle19331045a}. En particular, la causa eficiente o causa de movimiento se define como  \textquotedblleft la fuente del primer comienzo de cambio o descanso\textquotedblright y fue adoptada por muchos filósofos posteriores como Nicolás Maquiavelo y Francis Bacon.
	
	A principios de la época moderna, David Hume concebía la causalidad como un hecho psicológico, producto de nuestra experiencia. Entre la causa y el efecto existe una conexión necesaria que condiciona al efecto a sólo ocurrir después de la causa \cite{hume1896treatise}. Las ideas de Hume influenciaron a muchos de los posteriores filósofos y matemáticos que trabajaron en el área de la causalidad. Hume fue uno de los defensores del análisis de regularidad para explicar la causalidad. Otro partidario de este método fue John Stuart Mill (1806-1873).
	
	\subsection{La expulsión de la causalidad de la estadística y sus efectos}
	
	La historia de la causalidad desde el punto de matemático comienza en el siglo XIX. Francis Galton (1822-1911) en sus investigaciones acerca de la estabilidad de la dotación genética de las poblaciones descubrió el fenómeno de regresión a la media \cite{galton1886regression}. Inicialmente, trató de encontrarle una explicación causal, pero en el proceso descubrió la correlación, abriendo el camino para una nueva rama de la matemática: la estadística. Eventualmente, Galton se distanció de la causalidad y centró sus esfuerzos en esta otra rama.
	
	Karl Pearson, alumno de Galton, continuó con la tarea de excluir a la causalidad no solo de la estadística, sino de la ciencia misma. Para Pearson, la causalidad era prescindible para la ciencia. Argumentaba que las respuestas a todas las cuestiones se encontraban en los datos y que, consecuentemente, la correlación era un descriptor mucho más preciso de los procesos de la naturaleza que la causación. Parecía que la causalidad iba a ser sepultada completamente.
	
	Sin embargo, Pearson mismo no pudo desprenderse completamente de la causalidad. Escribió varios artículos junto a su asistente George Udny Yule(1871-1951) acerca de la \textquotedblleft correlación espúrea \textquotedblright, un término que no es posible explicar sin hacer uso de la causalidad. Pearson se dio cuenta de que era relativamente fácil de encontrar ejemplos en los que la correlación carecía de sentido. 
	
	Un caso típico de correlación espúrea es la ocurrencia de \textit{variables de confusión}(confounding), que ocurre cuando existe correlación entre dos variables pero ninguna es causa de la otra, sino que ambas son influenciadas a la vez por terceras variables. Un ejemplo famoso de este tipo consiste en que existe una fuerte correlación entre el consumo de chocolate per cápita en una nación y su número de ganadores del Premio Nobel. En respuesta a esta situación uno puede argumentar que el consumo de chocolate era abundante en los países de Occidente, donde también eran elegidos preferentemente los premios Nobel. Pero esta es una explicación causal, la cual, según Pearson, era irrelevante para el razonamiento científico.
	
	Otro ejemplo de correlación espúrea fue la encontrada por Yule al detectar una fuerte correlación entre la tasa de mortalidad de Inglaterra en un año y el porciento de matrimonios contraídos en ese mismo año en la Iglesia de Inglaterra. Lo que ocurrió fue que dos tendencias históricas coincidieron: el decrecimiento de la tasa de mortalidad y el de la membresía a la Iglesia de Inglaterra. Al disminuir ambos a la vez, existía una correlación positiva entre ambos, pero no una conexión causal.
	
	Pearson descubrió en 1889 uno de los tipos más famosos de correlación espúrea, que ocurre cuando dos poblaciones heterogéneas son mezcladas en una. Obtuvo medidas de la longitud y el ancho del cráneo de 806 hombres y 340 mujeres de las Catacumbas de París. Primero computó la correlación entre el ancho y la longitud en la población de los cráneos de hombres y luego hizo con la de las mujeres. En ambos casos no obtuvo un valor de correlación significativo. Sin embargo, al mezclar ambas poblaciones sí obtuvo una correlación significativa. Esto tiene sentido, porque un cráneo de longitud pequeña tiene más probabilidades de pertenecer a una mujer y que a su vez el ancho de este sea pequeño. Sin embargo, Pearson lo atribuyó a haber mezclado incorrectamente las poblaciones. Este ejemplo es un caso de un fenómeno más general conocido como la paradoja de Simpson.\cite{PearlMackenzie18}
	
	\subsection{Sewall Wright y los diagramas de caminos}
	Un punto de inflexión en la historia de la causalidad lo marcó el genetista Sewall Wright (1889-1988) cuando en 1920 publicó el artículo \textit{The relative importance of heredity and enviroment in determining the piebald pattern of guinea-pigs} \cite{wright1920relative}. El objetivo del trabajo de Wright por aquel entonces era determinar la causa de las variaciones en los patrones del color del pelo en los conejillos de indias. Wright dudaba que las variaciones genéticas fueran la única causa de este comportamiento y postuló que los factores de desarrollo en el útero de la madre y los factores ambientales eran también causantes de algunas variaciones. Al efecto que ejercía cada una de estas variables se le llama cantidades causales. Wright desarrolló entonces un modelo, conocido como diagrama de caminos (path diagram), que permitió calcular el valor de dichas cantidades. A partir de correlaciones medidas en los datos recopilados, se podía determinar el valor de las cantidades causales mediante ecuaciones algebraicas. Al final, Wright demostró que los factores de desarrollo erán mas importantes que los hereditarios. 
	
	El diagrama de caminos es el primer modelo causal que se haya publicado. Estableció por primera vez un puente entre las probabilidades y la causalidad.	A pesar de que no se necesita conocer todas las relaciones causales entre las variables de interés para sacar conclusiones causales, Wright deja un punto bien claro: no es posible llegar a conclusiones causales sin previamente establecer hipótesis causales. Esto implica que es imposible responder a una pregunta causal únicamente a partir de datos, lo cual supone una ruptura con los argumentos de los estadísticos de la época.
	
	Obviamente las hipótesis causales asumidas pueden ser incorrectas. En ese caso Wright argumentó que se podía usar su modelo en \textquotedblleft modo exploratorio\textquotedblright. Si los resultados que arrojaba resultaban contradictorios con los datos, entonces las hipótesis asumidas eran incorrectas y el modelo debía ser corregido.
	
	Contrario a lo que muchos piensan, el análisis causal no pretende demostrar que una variable causa a otra, o encontrar la causa de una variable. Ese es el terreno del descubrimiento causal. Wright comprendió desde el principio que el descubrimiento causal era mucho más difícil y quizá hasta imposible. En contraste, el análisis causal pretende representar el conocimiento causal en un lenguaje matemático, combinarlo con los datos, y responder a preguntas causales de valor práctico.\cite{PearlMackenzie18}		
	
	\subsection{Modelos de causalidad más relevantes}
	
	Hans Reichenbach introdujo el \textit{Principio de la Causa Común}(RCCP), el cual fue incorporado a una teoría probabilística de la causalidad. Este principio es significativo porque establece una conexión entre la estructura causal y la correlación probabilística, facilitando la inferencia causal a partir de correlaciones observadas. A menudo es visto como un antecedente de la \textit{Condición Causal de Markov}, la cual juega un papel fundamental en los modelos causales y en la inferencia causal. Sin embargo, el RCCP ha sido controvertido, siendo propuestos varios contra-ejemplos. Estos no refutan el principio completamente, sino que dan lugar a debates sobre su alcance e interpretación.\cite{sep-physics-Rpcc}
	
	Patrick Suppes se basó en las ideas de Hume para desarrollar su propia teoría de la causalidad. En su libro \textit{A probabilistic theory of causality}(1970)\cite{Suppes1968-SUPAPT}, Suppes plantea que el carácter de la causalidad en el lenguaje ordinario no es propiamente determinista, y que la principal debilidad en el análisis de Hume fue la omisión de consideraciones probabilísticas. Así mismo, da a conocer su propia definición de causalidad: un evento es la causa de otro si la aparición del primero es seguido con una alta probabilidad por la aparición del segundo, y no hay un tercer evento que se pueda utilizar para determinar la relación de probabilidad entre el primer y el segundo evento. Suppes propone entonces un framework probabilístico para el análisis de las relaciones causales. Presenta varias definiciones para los diferentes tipos de causas en un intento de distinguir las causas genuinas de las espúreas y las causas directas de las indirectas.
	
	Sin embargo, su trabajo no estuvo exento de críticas. En el artículo \textit{A critique of Suppes' theory of probabilistic causality} de Richard Otte, se ofrecen un conjunto de contra-ejemplos que muestran que la teoría de Suppes es defectuosa. En particular, destaca que las definiciones de Suppes fallan al diferenciar las causas genuinas de las espúreas, y las causas directas de las indirectas. Otte argumenta que no es posible diferenciar correctamente dichas causas utilizando únicamente relaciones probabilísticas, por lo que cualquier modificación menor en las definiciones de Suppes no logrará resolver estas dificultades.\cite{otte1981critique}
	
	El test de causalidad de Granger fue propuesto en 1969 por Clive Granger  para determinar cuando una serie de tiempo es útil para predecir otra \cite{10.2307/1912791}. Granger argumenta que en términos económicos la causalidad puede ser probada midiendo la capacidad de una serie de tiempo de predecir los valores futuros de otra serie de tiempo. En todo caso, los econometristas afirman que el test de Granger determina solo \textquotedblleft causalidad predictiva\textquotedblright. Granger enfatizó además que algunos estudios realizados en áreas fuera de la economía donde se utilizó el test de Granger arrojaron resultados ridículos. Esto se debe a que la definición de causalidad de Granger es demasiado restrictiva. El test de causalidad de Granger está diseñado para manejar relaciones entre dos variables, y puede arrojar resultados erróneos cuando las verdaderas relaciones de causalidad involucran tres o más variables. Además no puede capturar relaciones de causalidad no lineales. Sin embargo, se mantiene como un popular método de análisis causal en series de tiempo dada su simplicidad computacional. \cite{enwiki:1049120222}.	
	
	\subsubsection{Los desarrollos de Judea Pearl}
	Judea Pearl propone una jerarquía para clasificar los distintos niveles de inferencia causal, a la cual denomina \textquotedblleft la escalera de la causalidad\textquotedblright. Los tres niveles corresponden a las capacidades cognitivas que abarcan el razonamiento causal: ver, hacer e imaginar.
	
	El primer nivel pertenece a la asociación. La pregunta que lo caracteriza es: \textquestiondown Qué pasa si veo...?. Por ejemplo, un doctor luego de examinar a un paciente podría formularse la pregunta: \textquestiondown Dados los síntomas presentes, cuán probable es que el paciente posea una variante de la gripe?. La expresión $P(A\mid B)$ indica cuán probable es que el suceso $A$ ocurra dado que se sabe que el suceso $B$ ocurrió. La introducción de la Fórmula de la Probabilidad Total y la Fórmula de Bayes dan lugar al surgimiento del enfoque bayesiano de la Estadística en contraste con el enfoque frecuentista. La estadística bayesiana en conjunto con los modelos gráficos probabilistas sientan las bases para la modelación probabilista de la causalidad.
	
	El segundo nivel está determinado por las intervenciones. Preguntas representativas son: \textquestiondown Qué pasa si hacemos... ? o \textquestiondown Cómo?. A diferencia del primer nivel, se formulan preguntas en donde los hechos son forzados a ocurrir en vez de simplemente ser observados. Una pregunta de este nivel podría ser, por ejemplo: \textquestiondown Qué ocurriría si aumentamos el precio del producto X ? La expresión $P(A\mid do(B))$ nos dice cuán probable es la ocurrencia de $A$ dado que forzamos el suceso $B$ a ocurrir. La prueba aleatoria controlada (en inglés, \textit{Randomized Controlled Trial}, RCT) ha sido la herramienta tradicional en la estadística para determinar el valor de esta expresión. Sin embargo, este método presenta sus limitantes al poder ser muy costoso en algunos casos o ser imposible de realizar por cuestiones éticas. Uno de los avances en el terreno de la causalidad ha sido precisamente el poder computar el efecto de una intervención sin tener que realizarla.
	
	El tercer y último nivel corresponde a los contrafactuales. Preguntas representativas  son: \textquestiondown Qué pasaría si en vez de...? o \textquestiondown Por qué ? Responder a estas preguntas requiere imaginar mundos alternativos y comparararlos con el mundo real. Es en este nivel donde se formulan las preguntas más complejas e interesantes. Por ejemplo, luego de tomar un medicamento y aliviar su malestar, un paciente podría preguntarse: \textquestiondown Debo mi recuperación a haber tomado el medicamento ? \cite{PearlMackenzie18}
	
	Judea Pearl propone en los años 80 las redes bayesianas \cite{pearl1985bayesian}, un modelo que opera en el nivel 1 en su versión original. Estas se apoyan en la independencia condicional para construir una representación compacta de las relaciones entre las variables. A partir de un conjunto de evidencias, permiten estimar la probabilidad conjunta de un conjunto de variables de la red.
	
	Los desarrollos posteriores de Pearl se adentran en abarcar los otros dos niveles de la escalera de causalidad. El modelo causal estructural es uno de sus resultados más importantes \cite{pearl2016causal}. Este contiene los desarrollos teóricos necesarios para computar tanto intervenciones como contrafactuales. Precisamente en este modelo, conjuntamente con las redes bayesianas, se basa el marco teórico del presente trabajo.
	
	\section{Objetivos}
	El presente trabajo tiene como objetivo general el diseño y programación de una aplicación que permita su utilización en la solución de diversos problemas causales relevantes de un modelo estructural causal. La aplicación debe facilitar a usuarios no expertos en programación su empleo en la solución de diversos problemas de causalidad que surgen en la investigación científica. A su vez, se pueden identificar varios objetivos específicos:	
	\begin{enumerate}
		\item Resumir los aspectos teóricos fundamentales acerca de la teoría de grafos y la teoría de las probabilidades, que serán la base de los desarrollos teóricos que se expondrán durante la tesis. Hacer especial énfasis en el concepto de independencia condicional y sus principales propiedades y resultados derivados.
		\item Desarrollo de la teoría de las redes bayesianas como antecedente del modelo causal estructural de Pearl. Descripción de los algoritmos de inferencia en redes bayesianas. 
		\item Desarrollo del modelo causal estructural de Pearl. Exposición de los diferentes criterios y algoritmos para calcular intervenciones y contrafactuales. Desarrollo de los conceptos de mediación y atribución y sus principales aplicaciones. 
		\item Proponer algoritmos que haciendo uso de las redes bayesianas resuelvan el problema de la inferencia causal en un modelo causal estructural.
		\item Diseño e implementación del programa. Este debe permitir la creación de modelos causales estructurales, en los que poder ejecutar algoritmos de inferencia causal que permitan responder a preguntas causales correspondientes a predicciones, intervenciones, contrafactuales, atribución y análisis de mediación.		
		\item Experimentación. Exposición de un problema práctico en el que se muestren las características del software desarrollado.
	\end{enumerate}
	
	El presente trabajo se estructura como se detalla a continuación: En el capítulo 2 presentará toda la literatura consultada que contiene los resultados teóricos necesarios para la construcción del software. En el capítulo 3 se presenta la propuesta de software para resolver problemas de inferencia causal, mostrando las funcionalidades que ofrece así como los detalles técnicos de la implementación. Por último, en el capítulo 4 se muestra una aplicación práctica del programa en la que se utilizará un modelo causal para responder a preguntas causales acerca de la COVID 19.
\end{introduction}
